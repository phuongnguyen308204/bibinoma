from fastapi import APIRouter, HTTPException
from datetime import datetime
from .schemas import ChatRequest, ChatResponse
from .prompts import HEART_TO_HEART_SYSTEM_PROMPT
from .openai_client import client


router = APIRouter()


@router.post("/heart_to_heart", response_model=ChatResponse)
async def heart_to_heart_chat(request: ChatRequest):
    try:
        memories_context = ""
        if request.memories:
            normalized = []
            import json
            for m in request.memories:
                try:
                    if isinstance(m, str) and m.strip().startswith("{"):
                        parsed = json.loads(m)
                        text = parsed.get("memory") or m
                    elif isinstance(m, dict):
                        text = m.get("memory") or str(m)
                    else:
                        text = str(m)
                except Exception:
                    text = str(m)
                if text:
                    normalized.append(text)
            if normalized:
                memories_context = "\n\nK√Ω ·ª©c t·ª´ c√°c cu·ªôc tr√≤ chuy·ªán tr∆∞·ªõc:\n" + "".join([f"- {m}\n" for m in normalized])

        system_prompt_with_memories = HEART_TO_HEART_SYSTEM_PROMPT + memories_context

        messages = [{"role": "system", "content": system_prompt_with_memories}]

        if request.chat_history:
            recent_history = request.chat_history[-10:] if len(request.chat_history) > 10 else request.chat_history
            for msg in recent_history:
                messages.append({"role": msg.role, "content": msg.content})

        messages.append({"role": "user", "content": request.message})

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=500,
            temperature=0.8,
        )

        assistant_message = response.choices[0].message.content

        current_memories_text = ""
        if request.memories:
            current_memories_text = "\n\nK√Ω ·ª©c hi·ªán t·∫°i ƒë√£ l∆∞u (ƒë·ªÉ tham kh·∫£o tr√°nh tr√πng l·∫∑p):\n" + "\n".join([f"- {m}" for m in request.memories])

        memories_prompt = f"""
                Nhi·ªám v·ª•: T·ª´ c·∫∑p c√¢u sau (user + Bibi), h√£y tr√≠ch xu·∫•t M·ªòT c√¢u ti·∫øng Vi·ªát ng·∫Øn g·ªçn m√¥ t·∫£ th√¥ng tin quan tr·ªçng nh·∫•t n√™n l∆∞u l√†m memory d√†i h·∫°n.
                - N·∫øu kh√¥ng c√≥ g√¨ ƒë√°ng l∆∞u, tr·∫£ v·ªÅ {{}} r·ªóng.
                - V√≠ d·ª• c√¢u: "User t√™n Nguy√™n", "User m·ªõi chia tay v√† r·∫•t bu·ªìn", "User th√≠ch ch·∫°y b·ªô s√°ng".
                - Tr√°nh tr√πng l·∫∑p v·ªõi danh s√°ch memories hi·ªán c√≥ (n·∫øu c√πng n·ªôi dung, coi nh∆∞ ƒë√£ c√≥).

                User: {request.message}
                Bibi: {assistant_message}
                {current_memories_text}

                H√£y tr·∫£ v·ªÅ JSON ƒë√∫ng chu·∫©n:
                {{
                  "memory": "<m·ªôt_c√¢u_ti·∫øng_Vi·ªát_ng·∫Øn>",
                  "timestamp": "{datetime.now().isoformat()}"
                }}
                N·∫øu kh√¥ng c√≥ g√¨ ƒë·ªÉ l∆∞u, tr·∫£ v·ªÅ {{}}.
                """

        memories_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": memories_prompt}],
            max_tokens=200,
            temperature=0.3,
        )

        try:
            memories_text = memories_response.choices[0].message.content or "{}"
            if memories_text.startswith("```json"):
                memories_text = memories_text.replace("```json", "").replace("```", "").strip()
            elif memories_text.startswith("```"):
                memories_text = memories_text.replace("```", "").strip()
            import json
            parsed = json.loads(memories_text)
            if isinstance(parsed, dict) and parsed.get("memory"):
                memories_dict = {"memory": parsed.get("memory"), "timestamp": parsed.get("timestamp") or datetime.now().isoformat()}
            else:
                memories_dict = {}
        except Exception:
            memories_dict = {}

        if memories_dict and "memory" in memories_dict and memories_dict["memory"]:
            bibi_with_guidance = assistant_message + "\n\n[üìã L√™n k·∫ø ho·∫°ch v·ªõi Noma](/chat/planning)"
        else:
            bibi_with_guidance = assistant_message

        return ChatResponse(user=request.message, noma=bibi_with_guidance, memories=memories_dict)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")



@router.post("/heart_to_heart_greeting", response_model=ChatResponse)
async def heart_to_heart_greeting(request: ChatRequest):
    try:
        latest_memory_text = ""
        if request.memories:
            import json
            from datetime import datetime as dt
            latest_ts = None
            for m in request.memories:
                try:
                    if isinstance(m, str) and m.strip().startswith("{"):
                        parsed = json.loads(m)
                    elif isinstance(m, dict):
                        parsed = m
                    else:
                        parsed = {"memory": str(m)}
                except Exception:
                    parsed = {"memory": str(m)}

                mem_text = (parsed.get("memory") or "").strip()
                ts_raw = (parsed.get("timestamp") or "").strip()
                ts_val = None
                if ts_raw:
                    try:
                        ts_val = dt.fromisoformat(ts_raw)
                    except Exception:
                        ts_val = None

                if mem_text:
                    if latest_ts is None and latest_memory_text == "":
                        latest_memory_text = mem_text
                    if ts_val is not None:
                        if latest_ts is None or ts_val > latest_ts:
                            latest_ts = ts_val
                            latest_memory_text = mem_text

        if latest_memory_text:
            context_line = f"B·ªëi c·∫£nh g·∫ßn nh·∫•t: '{latest_memory_text}'."
        else:
            context_line = ""

        prompt = (
            "B·∫°n l√† Bibi - ng∆∞·ªùi b·∫°n t√¢m s·ª± ·∫•m √°p.\n"
            "NHI·ªÜM V·ª§: T·∫°o ƒë√∫ng M·ªòT c√¢u h·ªèi h·ªèi thƒÉm ng·∫Øn g·ªçn, ƒë·ªìng c·∫£m cho h√¥m nay.\n"
            "B·∫ÆT BU·ªòC: N·∫øu c√≥ b·ªëi c·∫£nh, PH·∫¢I nh·∫Øc NG·∫ÆN t·ªõi b·ªëi c·∫£nh ƒë√≥ trong ch√≠nh c√¢u h·ªèi.\n"
            "V√ç D·ª§: 'Bibi nh·ªõ chuy·ªán chia tay g·∫ßn ƒë√¢y c·ªßa b·∫°n, h√¥m nay b·∫°n th·∫•y sao r·ªìi?'\n"
            "ƒê·ªäNH D·∫†NG: M·ªôt c√¢u duy nh·∫•t, kh√¥ng xu·ªëng d√≤ng, kh√¥ng markdown, kh√¥ng gi·∫£i th√≠ch.\n"
            f"{context_line}"
        )

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=80,
            temperature=0.3,
        )

        assistant_message = response.choices[0].message.content
        return ChatResponse(user="", noma=assistant_message, memories={})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")